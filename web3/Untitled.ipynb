{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98269f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web3.py is a Python library built for interacting with the Ethereum blockchain. \n",
    "from web3 import Web3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf381f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<web3.main.Web3 at 0x10f298c40>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Infura is a Consensys product we will use as our node to connect to the Ethereum blockchain\n",
    "infura_url = \"https://mainnet.infura.io/v3/80bb32109e1e483eb0526e05db660a47\"\n",
    "w3 = Web3(Web3.HTTPProvider(infura_url))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e78771bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "balance = w3.eth.get_balance('0x0601746E39294055C1F8054ac979A9797301fB4b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cfec600",
   "metadata": {},
   "outputs": [],
   "source": [
    "abi = json.loads('[{\"constant\":true,\"inputs\":[],\"name\":\"mintingFinished\",\"outputs\":[{\"name\":\"\",\"type\":\"bool\"}],\"payable\":false,\"type\":\"function\"},{\"constant\":true,\"inputs\":[],\"name\":\"name\",\"outputs\":[{\"name\":\"\",\"type\":\"string\"}],\"payable\":false,\"type\":\"function\"},{\"constant\":false,\"inputs\":[{\"name\":\"_spender\",\"type\":\"address\"},{\"name\":\"_value\",\"type\":\"uint256\"}],\"name\":\"approve\",\"outputs\":[],\"payable\":false,\"type\":\"function\"},{\"constant\":true,\"inputs\":[],\"name\":\"totalSupply\",\"outputs\":[{\"name\":\"\",\"type\":\"uint256\"}],\"payable\":false,\"type\":\"function\"},{\"constant\":false,\"inputs\":[{\"name\":\"_from\",\"type\":\"address\"},{\"name\":\"_to\",\"type\":\"address\"},{\"name\":\"_value\",\"type\":\"uint256\"}],\"name\":\"transferFrom\",\"outputs\":[],\"payable\":false,\"type\":\"function\"},{\"constant\":true,\"inputs\":[],\"name\":\"decimals\",\"outputs\":[{\"name\":\"\",\"type\":\"uint256\"}],\"payable\":false,\"type\":\"function\"},{\"constant\":false,\"inputs\":[],\"name\":\"unpause\",\"outputs\":[{\"name\":\"\",\"type\":\"bool\"}],\"payable\":false,\"type\":\"function\"},{\"constant\":false,\"inputs\":[{\"name\":\"_to\",\"type\":\"address\"},{\"name\":\"_amount\",\"type\":\"uint256\"}],\"name\":\"mint\",\"outputs\":[{\"name\":\"\",\"type\":\"bool\"}],\"payable\":false,\"type\":\"function\"},{\"constant\":true,\"inputs\":[],\"name\":\"paused\",\"outputs\":[{\"name\":\"\",\"type\":\"bool\"}],\"payable\":false,\"type\":\"function\"},{\"constant\":true,\"inputs\":[{\"name\":\"_owner\",\"type\":\"address\"}],\"name\":\"balanceOf\",\"outputs\":[{\"name\":\"balance\",\"type\":\"uint256\"}],\"payable\":false,\"type\":\"function\"},{\"constant\":false,\"inputs\":[],\"name\":\"finishMinting\",\"outputs\":[{\"name\":\"\",\"type\":\"bool\"}],\"payable\":false,\"type\":\"function\"},{\"constant\":false,\"inputs\":[],\"name\":\"pause\",\"outputs\":[{\"name\":\"\",\"type\":\"bool\"}],\"payable\":false,\"type\":\"function\"},{\"constant\":true,\"inputs\":[],\"name\":\"owner\",\"outputs\":[{\"name\":\"\",\"type\":\"address\"}],\"payable\":false,\"type\":\"function\"},{\"constant\":true,\"inputs\":[],\"name\":\"symbol\",\"outputs\":[{\"name\":\"\",\"type\":\"string\"}],\"payable\":false,\"type\":\"function\"},{\"constant\":false,\"inputs\":[{\"name\":\"_to\",\"type\":\"address\"},{\"name\":\"_value\",\"type\":\"uint256\"}],\"name\":\"transfer\",\"outputs\":[],\"payable\":false,\"type\":\"function\"},{\"constant\":false,\"inputs\":[{\"name\":\"_to\",\"type\":\"address\"},{\"name\":\"_amount\",\"type\":\"uint256\"},{\"name\":\"_releaseTime\",\"type\":\"uint256\"}],\"name\":\"mintTimelocked\",\"outputs\":[{\"name\":\"\",\"type\":\"address\"}],\"payable\":false,\"type\":\"function\"},{\"constant\":true,\"inputs\":[{\"name\":\"_owner\",\"type\":\"address\"},{\"name\":\"_spender\",\"type\":\"address\"}],\"name\":\"allowance\",\"outputs\":[{\"name\":\"remaining\",\"type\":\"uint256\"}],\"payable\":false,\"type\":\"function\"},{\"constant\":false,\"inputs\":[{\"name\":\"newOwner\",\"type\":\"address\"}],\"name\":\"transferOwnership\",\"outputs\":[],\"payable\":false,\"type\":\"function\"},{\"anonymous\":false,\"inputs\":[{\"indexed\":true,\"name\":\"to\",\"type\":\"address\"},{\"indexed\":false,\"name\":\"value\",\"type\":\"uint256\"}],\"name\":\"Mint\",\"type\":\"event\"},{\"anonymous\":false,\"inputs\":[],\"name\":\"MintFinished\",\"type\":\"event\"},{\"anonymous\":false,\"inputs\":[],\"name\":\"Pause\",\"type\":\"event\"},{\"anonymous\":false,\"inputs\":[],\"name\":\"Unpause\",\"type\":\"event\"},{\"anonymous\":false,\"inputs\":[{\"indexed\":true,\"name\":\"owner\",\"type\":\"address\"},{\"indexed\":true,\"name\":\"spender\",\"type\":\"address\"},{\"indexed\":false,\"name\":\"value\",\"type\":\"uint256\"}],\"name\":\"Approval\",\"type\":\"event\"},{\"anonymous\":false,\"inputs\":[{\"indexed\":true,\"name\":\"from\",\"type\":\"address\"},{\"indexed\":true,\"name\":\"to\",\"type\":\"address\"},{\"indexed\":false,\"name\":\"value\",\"type\":\"uint256\"}],\"name\":\"Transfer\",\"type\":\"event\"}]')\n",
    "address = \"0xd26114cd6EE289AccF82350c8d8487fedB8A0C07\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8eb384e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "contract = w3.eth.contract(address=address, abi=abi)\n",
    "total_supply = contract.functions.totalSupply().call()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "103b01d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decimal('140245398.245132780789239631')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w3.fromWei(total_supply, 'ether')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91c2ade5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OMGToken'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contract.functions.name().call()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f7330c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2312b592",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2aaced",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93f88f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Webscraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2df4b220",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,csv,time #\"time\" helps to break for the url visiting \n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup   # Need to install this package manually using pip\n",
    "                                # We only import part of the Beautifulsoup4\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f62d230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATVI</td>\n",
       "      <td>Activision Blizzard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>Alphabet (Class A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>Alphabet (Class C)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T</td>\n",
       "      <td>AT&amp;T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHTR</td>\n",
       "      <td>Charter Communications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CMCSA</td>\n",
       "      <td>Comcast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DISCA</td>\n",
       "      <td>Discovery (Series A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DISCK</td>\n",
       "      <td>Discovery (Series C)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DISH</td>\n",
       "      <td>Dish Network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EA</td>\n",
       "      <td>Electronic Arts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ticker                    Name\n",
       "0   ATVI     Activision Blizzard\n",
       "1  GOOGL      Alphabet (Class A)\n",
       "2   GOOG      Alphabet (Class C)\n",
       "3      T                    AT&T\n",
       "4   CHTR  Charter Communications\n",
       "5  CMCSA                 Comcast\n",
       "6  DISCA    Discovery (Series A)\n",
       "7  DISCK    Discovery (Series C)\n",
       "8   DISH            Dish Network\n",
       "9     EA         Electronic Arts"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# path = 'ticker_list.csv'\n",
    "companyListFile = pd.read_csv('/Users/munjismac/code/munjik/personal-projects/web3/ticker_list.csv')\n",
    "companyListFile.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e5ada41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# moving the first two above \n",
    "# path = 'ticker_list.csv'\n",
    "# companyListFile = pd.read_csv('/Users/munjismac/code/munjik/personal-projects/web3/ticker_list.csv)\n",
    "IndexLinksFile = \"IndexLinks.csv\" # a csv file (output of the current script) with the list of index links for each firm (the file has a line with headers)\n",
    "\n",
    "def getIndexLink(tickerCode,FormType):\n",
    "    csvOutput = open(IndexLinksFile,\"a+b\") # \"a+b\" indicates that we are adding lines rather than replacing lines\n",
    "    csvWriter = csv.writer(csvOutput, quoting = csv.QUOTE_NONNUMERIC)\n",
    "    \n",
    "    urlLink = \"https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK=\"+tickerCode+\"&type=\"+FormType+\"&dateb=&owner=exclude&count=100\"\n",
    "    pageRequest = urllib.Request(urlLink)\n",
    "    pageOpen = urllib.urlopen(pageRequest)\n",
    "    pageRead = pageOpen.read()\n",
    "    \n",
    "    soup = BeautifulSoup(pageRead,\"html.parser\")\n",
    "    \n",
    "    #Check if there is a table to extract / code exists in edgar database\n",
    "    try:\n",
    "        table = soup.find(\"table\", { \"class\" : \"tableFile2\" })\n",
    "    except:\n",
    "        print(\"No tables found or no matching ticker symbol for ticker symbol for\"+tickerCode)\n",
    "        return -1\n",
    "\n",
    "    docIndex = 1\n",
    "    for row in table.findAll(\"tr\"):\n",
    "        cells = row.findAll(\"td\")\n",
    "        if len(cells)==5:\n",
    "            if cells[0].text.strip() == FormType:\n",
    "                link = cells[1].find(\"a\",{\"id\": \"documentsbutton\"})\n",
    "                docLink = \"https://www.sec.gov\"+link['href']\n",
    "                description = cells[2].text.encode('utf8').strip() #strip take care of the space in the beginning and the end\n",
    "                filingDate = cells[3].text.encode('utf8').strip()\n",
    "                newfilingDate = filingDate.replace(\"-\",\"_\")  ### <=== Change date format from 2012-1-1 to 2012_1_1 so it can be used as part of 10-K file names\n",
    "                csvWriter.writerow([tickerCode, docIndex, docLink, description, filingDate,newfilingDate])\n",
    "                docIndex = docIndex + 1\n",
    "    csvOutput.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a15acf5b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not DataFrame",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/m3/fzmpbzjs1tjcq9gdml2487w40000gn/T/ipykernel_94051/1525288420.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/m3/fzmpbzjs1tjcq9gdml2487w40000gn/T/ipykernel_94051/1525288420.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnbSecPause\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;31m### <=== Type your pausing time in seconds between each batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mcsvFile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompanyListFile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#<===open and read from a csv file with the list of company ticker symbols (the file has a line with headers)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mcsvReader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvFile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mcsvData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvReader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not DataFrame"
     ]
    }
   ],
   "source": [
    "def main():  \n",
    "    FormType = \"10-K\"   ### <=== Type your document type here\n",
    "    nbDocPause = 10 ### <=== Type your number of documents to download in one batch\n",
    "    nbSecPause = 0 ### <=== Type your pausing time in seconds between each batch\n",
    "\n",
    "    csvFile = open(companyListFile,\"r\") #<===open and read from a csv file with the list of company ticker symbols (the file has a line with headers)\n",
    "    csvReader = csv.reader(csvFile,delimiter=\",\")\n",
    "    csvData = list(csvReader)\n",
    "    \n",
    "    csvOutput = open(IndexLinksFile,\"a+b\") #<===open and write to a csv file which will include the list of index links. New rows will be appended.\n",
    "    csvWriter = csv.writer(csvOutput, quoting = csv.QUOTE_NONNUMERIC)\n",
    "    \n",
    "    csvWriter.writerow([\"Ticker\", \"DocIndex\",\"IndexLink\", \"Description\", \"FilingDate\",\"NewFilingDate\"])\n",
    "    csvOutput.close()\n",
    "    \n",
    "    i = 1\n",
    "    for rowData in csvData[1:]:\n",
    "        ticker = rowData[0]\n",
    "        getIndexLink(ticker,FormType)\n",
    "        if i%nbDocPause == 0:\n",
    "            print(i)\n",
    "            print(\"Pause for \"+str(nbSecPause)+\" second .... \")\n",
    "            time.sleep(float(nbSecPause))\n",
    "        i=i+1\n",
    "       \n",
    "    csvFile.close()\n",
    "    print(\"done!\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87419cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "IndexLinksFile = \"IndexLinks.csv\"  #a csv file (output of the 1GetIndexLinks.py script) with the list of index links for each firm (the file has a line with headers)\n",
    "Form10kListFile = \"10kList.csv\"    #a csv file (output of the current script) with the list of 10-K links for each firm (the file has a line with headers)\n",
    "\n",
    "def get10kLink(tickerCode, docIndex, docLink, description, filingDate, newFilingDate, FormType):\n",
    "    csvOutput = open(Form10kListFile,\"a+b\")\n",
    "    csvWriter = csv.writer(csvOutput, quoting = csv.QUOTE_NONNUMERIC)\n",
    "    \n",
    "    pageRequest = urllib2.Request(docLink)\n",
    "    pageOpen = urllib2.urlopen(pageRequest)\n",
    "    pageRead = pageOpen.read()\n",
    "    \n",
    "    soup = BeautifulSoup(pageRead,\"html.parser\")\n",
    "\n",
    "    #Check if there is a table to extract / code exists in edgar database\n",
    "    try:\n",
    "        table = soup.find(\"table\", { \"summary\" : \"Document Format Files\" })\n",
    "    except:\n",
    "        print (\"No tables found for link \"+docLink)\n",
    "        \n",
    "    for row in table.findAll(\"tr\"):\n",
    "        cells = row.findAll(\"td\")\n",
    "        if len(cells)==5:\n",
    "            if cells[3].text.strip() == FormType:\n",
    "                link = cells[2].find(\"a\")\n",
    "                formLink = \"https://www.sec.gov\"+link['href']\n",
    "                formName = link.text.encode('utf8').strip()\n",
    "                csvWriter.writerow([tickerCode, docIndex, docLink, description, filingDate, newFilingDate, formLink,formName])\n",
    "    csvOutput.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58526045",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'IndexLinks.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/m3/fzmpbzjs1tjcq9gdml2487w40000gn/T/ipykernel_94051/1968470827.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/m3/fzmpbzjs1tjcq9gdml2487w40000gn/T/ipykernel_94051/1968470827.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnbSecPause\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;31m### <=== Type your pausing time in seconds between each batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mcsvFile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIndexLinksFile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#<===Open and read from a csv file with the list of index links for each firm (the file has a line with headers)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mcsvReader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvFile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mcsvData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvReader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'IndexLinks.csv'"
     ]
    }
   ],
   "source": [
    "def main():  \n",
    "    FormType = \"10-K\"   ### <=== Type your document type here\n",
    "    nbDocPause = 10 ### <=== Type your number of documents to download in one batch\n",
    "    nbSecPause = 1 ### <=== Type your pausing time in seconds between each batch\n",
    "\n",
    "    csvFile = open(IndexLinksFile,\"r\") #<===Open and read from a csv file with the list of index links for each firm (the file has a line with headers)\n",
    "    csvReader = csv.reader(csvFile,delimiter=\",\")\n",
    "    csvData = list(csvReader)\n",
    "    \n",
    "    csvOutput = open(Form10kListFile,\"a+b\") #<===open and write to a csv file which will include the list of 10-K links. New rows will be appended.\n",
    "    csvWriter = csv.writer(csvOutput, quoting = csv.QUOTE_NONNUMERIC)\n",
    "    \n",
    "    csvWriter.writerow([\"Ticker\", \"DocIndex\", \"IndexLink\", \"Description\", \"FilingDate\", \"NewFilingDate\", \"Form10KLink\",\"Form10KName\"])\n",
    "    csvOutput.close()\n",
    "    \n",
    "    i = 1\n",
    "    for rowData in csvData[1:]:\n",
    "        Ticker = rowData[0]\n",
    "        DocIndex = rowData[1]\n",
    "        DocLink = rowData[2]\n",
    "        Description = rowData[3]\n",
    "        FileDate = rowData[4]\n",
    "        NewFileDate = rowData[5]\n",
    "        \n",
    "        get10kLink(Ticker,DocIndex,DocLink,Description,FileDate,NewFileDate,FormType)\n",
    "        if i%nbDocPause == 0:\n",
    "            print(i)\n",
    "            prin(\"Pause for \"+str(nbSecPause)+\" second .... \")\n",
    "            time.sleep(float(nbSecPause))\n",
    "        i=i+1\n",
    "       \n",
    "    csvFile.close()\n",
    "    print(\"done!\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8143290d",
   "metadata": {},
   "outputs": [],
   "source": [
    "htmlSubPath = \"./HTML/\" #<===The subfolder with the 10-K files in HTML format\n",
    "\n",
    "Form10kListFile = \"10kList.csv\" #a csv file (output of the 2Get10kLinks.py script) with the list of 10-K links\n",
    "logFile = \"10kDownloadLog.csv\" #a csv file (output of the current script) with the download history of 10-K forms\n",
    "\n",
    "def dowmload10k(tickerCode, docIndex, docLink, description, filingDate, newFilingDate, formLink,formName):\n",
    "    csvOutput = open(logFile,\"a+b\")\n",
    "    csvWriter = csv.writer(csvOutput, quoting = csv.QUOTE_NONNUMERIC)\n",
    "\n",
    "    try:\n",
    "        pageRequest = urllib2.Request(formLink)\n",
    "        pageOpen = urllib2.urlopen(pageRequest)\n",
    "        pageRead = pageOpen.read()\n",
    "\n",
    "        htmlname = tickerCode+\"_\"+docIndex+\"_\"+newFilingDate+\".htm\"\n",
    "        htmlpath = htmlSubPath+htmlname\n",
    "        htmlfile = open(htmlpath,'wb')\n",
    "        htmlfile.write(pageRead)\n",
    "        htmlfile.close()\n",
    "        csvWriter.writerow([tickerCode, docIndex, docLink, description, filingDate, newFilingDate, formLink,formName, htmlname, \"\"])\n",
    "    except:\n",
    "        csvWriter.writerow([tickerCode, docIndex, docLink, description, filingDate, newFilingDate, formLink,formName, \"\",\"not downloaded\"])\n",
    "\n",
    "    csvOutput.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d1e50d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '10kList.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/m3/fzmpbzjs1tjcq9gdml2487w40000gn/T/ipykernel_94051/2664941920.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/m3/fzmpbzjs1tjcq9gdml2487w40000gn/T/ipykernel_94051/2664941920.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mFormYears\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'2014'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'2015'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m### <=== Type the years of documents to download here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mcsvFile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mForm10kListFile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#<===A csv file with the list of company ticker symbols (the file has a line with headers)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mcsvReader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvFile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mcsvData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvReader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '10kList.csv'"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    if not os.path.isdir(htmlSubPath):  ### <=== keep all HTML files in this subfolder\n",
    "        os.makedirs(htmlSubPath)\n",
    "    \n",
    "    FormType = \"10-K\"   ### <=== Type your document type here\n",
    "    nbDocPause = 5 ### <=== Type your number of documents to download in one batch\n",
    "    nbSecPause = 1 ### <=== Type your pausing time in seconds between each batch\n",
    "\n",
    "    FormYears = ['2014','2015'] ### <=== Type the years of documents to download here\n",
    "\n",
    "    csvFile = open(Form10kListFile,\"r\") #<===A csv file with the list of company ticker symbols (the file has a line with headers)\n",
    "    csvReader = csv.reader(csvFile,delimiter=\",\")\n",
    "    csvData = list(csvReader)\n",
    "\n",
    "    csvOutput = open(logFile,\"a+b\")\n",
    "    csvWriter = csv.writer(csvOutput, quoting = csv.QUOTE_NONNUMERIC)\n",
    "\n",
    "    csvWriter.writerow([\"Ticker\", \"DocIndex\", \"IndexLink\", \"Description\", \"FilingDate\", \"NewFilingDate\", \"Form10KLink\",\"Form10KName\", \"FileName\",\"Note\"])\n",
    "    csvOutput.close()\n",
    "    \n",
    "    i = 1\n",
    "    for rowData in csvData[1:]:\n",
    "        Ticker = rowData[0]\n",
    "        DocIndex = rowData[1]\n",
    "        IndexLink = rowData[2]\n",
    "        Description = rowData[3]\n",
    "        FilingDate = rowData[4]\n",
    "        NewFilingDate = rowData[5]\n",
    "        FormLink = rowData[6]\n",
    "        FormName = rowData[7]\n",
    "        for year in FormYears:\n",
    "            if year in FilingDate:\n",
    "                if \".htm\" in FormName:\n",
    "                    dowmload10k(Ticker, DocIndex, IndexLink, Description, FilingDate, NewFilingDate, FormLink,FormName)\n",
    "                elif \".txt\" in FormName:\n",
    "                    csvOutput = open(logFile,\"a+b\")\n",
    "                    csvWriter = csv.writer(csvOutput, quoting = csv.QUOTE_NONNUMERIC)\n",
    "                    csvWriter.writerow([Ticker, DocIndex, IndexLink, Description, FilingDate, NewFilingDate, FormLink,FormName, \"\",\"Text format\"])\n",
    "                    csvOutput.close()\n",
    "                else:\n",
    "                    csvOutput = open(logFile,\"a+b\")\n",
    "                    csvWriter = csv.writer(csvOutput, quoting = csv.QUOTE_NONNUMERIC)\n",
    "                    csvWriter.writerow([Ticker, DocIndex, IndexLink, Description, FilingDate, NewFilingDate, FormLink,FormName,\"\", \"No form\"])\n",
    "                    csvOutput.close()\n",
    "            \n",
    "        if i%nbDocPause == 0:\n",
    "            print(i)\n",
    "            print(\"Pause for \"+str(nbSecPause)+\" second .... \")\n",
    "            time.sleep(float(nbSecPause))\n",
    "        i=i+1\n",
    "       \n",
    "    csvFile.close()\n",
    "    print(\"done!\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "\tmain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff84dee2",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '10kDownloadLog.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/m3/fzmpbzjs1tjcq9gdml2487w40000gn/T/ipykernel_94051/626547257.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/m3/fzmpbzjs1tjcq9gdml2487w40000gn/T/ipykernel_94051/626547257.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxtSubPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mcsvFile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDownloadLogFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#<===A csv file with the list of 10k file names (the file should have no header)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0mcsvReader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvFile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mcsvData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvReader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '10kDownloadLog.csv'"
     ]
    }
   ],
   "source": [
    "htmlSubPath = \"./HTML/\" #<===The subfolder with the 10-K files in HTML format\n",
    "txtSubPath = \"./txt/\" #<===The subfolder with the extracted text files\n",
    "\n",
    "DownloadLogFile = \"10kDownloadLog.csv\" #a csv file (output of the 3DownloadHTML.py script) with the download history of 10-K forms\n",
    "ReadLogFile = \"10kReadlog.csv\" #a csv file (output of the current script) showing whether item 1 is successfully extracted from 10-K forms\n",
    "\n",
    "def readHTML(file_name):\n",
    "    input_path = htmlSubPath+file_name\n",
    "    output_path = txtSubPath+file_name.replace(\".htm\",\".txt\")\n",
    "    \n",
    "\n",
    "    input_file = open(input_path,'rb')\n",
    "    page = input_file.read()  #<===Read the HTML file into Python\n",
    "\n",
    "\n",
    "    #Pre-processing the html content by removing extra white space and combining then into one line.\n",
    "    page = page.strip()  #<=== remove white space at the beginning and end\n",
    "    page = page.replace('\\n', ' ') #<===replace the \\n (new line) character with space\n",
    "    page = page.replace('\\r', '') #<===replace the \\r (carriage returns -if you're on windows) with space\n",
    "    page = page.replace('&nbsp;', ' ') #<===replace \"&nbsp;\" (a special character for space in HTML) with space. \n",
    "    page = page.replace('&#160;', ' ') #<===replace \"&#160;\" (a special character for space in HTML) with space.\n",
    "    while '  ' in page:\n",
    "        page = page.replace('  ', ' ') #<===remove extra space\n",
    "\n",
    "    #Using regular expression to extract texts that match a pattern\n",
    "        \n",
    "    #Define pattern for regular expression.\n",
    "        #The following patterns find ITEM 1 and ITEM 1A as diplayed as subtitles\n",
    "        #(.+?) represents everything between the two subtitles\n",
    "    #If you want to extract something else, here is what you should change\n",
    "\n",
    "    #Define a list of potential patterns to find ITEM 1 and ITEM 1A as subtitles   \n",
    "    regexs = ('bold;\\\">\\s*Item 1\\.(.+?)bold;\\\">\\s*Item 1A\\.',   #<===pattern 1: with an attribute bold before the item subtitle\n",
    "              'b>\\s*Item 1\\.(.+?)b>\\s*Item 1A\\.',               #<===pattern 2: with a tag <b> before the item subtitle\n",
    "              'Item 1\\.\\s*<\\/b>(.+?)Item 1A\\.\\s*<\\/b>',         #<===pattern 3: with a tag <\\b> after the item subtitle          \n",
    "              'Item 1\\.\\s*Business\\.\\s*<\\/b(.+?)Item 1A\\.\\s*Risk Factors\\.\\s*<\\/b') #<===pattern 4: with a tag <\\b> after the item+description subtitle \n",
    "\n",
    "    #Now we try to see if a match can be found...\n",
    "    for regex in regexs:\n",
    "        match = re.search (regex, page, flags=re.IGNORECASE)  #<===search for the pattern in HTML using re.search from the re package. Ignore cases.\n",
    "\n",
    "        #If a match exist....\n",
    "        if match:\n",
    "            #Now we have the extracted content still in an HTML format\n",
    "            #We now turn it into a beautiful soup object\n",
    "            #so that we can remove the html tags and only keep the texts\n",
    "            \n",
    "            soup = BeautifulSoup(match.group(1), \"html.parser\") #<=== match.group(1) returns the texts inside the parentheses (.*?) \n",
    "            \n",
    "\n",
    "            #soup.text removes the html tags and only keep the texts\n",
    "            rawText = soup.text.encode('utf8') #<=== you have to change the encoding the unicodes\n",
    "\n",
    "           \n",
    "            #remove space at the beginning and end and the subtitle \"business\" at the beginning\n",
    "            #^ matches the beginning of the text\n",
    "            outText = re.sub(\"^business\\s*\",\"\",rawText.strip(),flags=re.IGNORECASE)\n",
    "            \n",
    "            output_file = open(output_path, \"w\")\n",
    "            output_file.write(outText)  \n",
    "            output_file.close()\n",
    "            \n",
    "            break  #<=== if a match is found, we break the for loop. Otherwise the for loop continues\n",
    "\n",
    "    input_file.close()    \n",
    "\n",
    "    return match\n",
    "\n",
    "def main():\n",
    "\n",
    "    if not os.path.isdir(txtSubPath):  ### <=== keep all texts files in this subfolder\n",
    "        os.makedirs(txtSubPath)\n",
    "        \n",
    "    csvFile = open(DownloadLogFile, \"rb\") #<===A csv file with the list of 10k file names (the file should have no header)\n",
    "    csvReader = csv.reader(csvFile,delimiter=\",\")\n",
    "    csvData = list(csvReader)\n",
    "    \n",
    "    logFile = open(ReadLogFile, \"a+b\") #<===A log file to track which file is successfully extracted\n",
    "    logWriter = csv.writer(logFile, quoting = csv.QUOTE_NONNUMERIC)\n",
    "    logWriter.writerow([\"filename\",\"extracted\"])\n",
    "\n",
    "    i=1\n",
    "    for rowData in csvData[1:]:\n",
    "##        Ticker = rowData[0]\n",
    "##        DocIndex = rowData[1]\n",
    "##        IndexLink = rowData[2]\n",
    "##        Description = rowData[3]\n",
    "##        FilingDate = rowData[4]\n",
    "##        NewFilingDate = rowData[5]\n",
    "##        FormLink = rowData[6]\n",
    "##        FormName = rowData[7]\n",
    "        FileName = rowData[8]\n",
    "        \n",
    "        if \".htm\" in FileName:        \n",
    "            match=readHTML(FileName)\n",
    "            if match:\n",
    "                logWriter.writerow([FileName,\"yes\"])\n",
    "            else:\n",
    "                logWriter.writerow([FileName,\"no\"])\n",
    "        i=i+1\n",
    "        \n",
    "    csvFile.close()\n",
    "\n",
    "    logFile.close()\n",
    "    print(\"done!\")\n",
    "            \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6893f648",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
