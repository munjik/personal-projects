{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c19649a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'geopy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimpleImputer\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgeopy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeocoders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Nominatim\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'geopy'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from geopy.geocoders import Nominatim\n",
    "import warnings\n",
    "import requests\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437d6ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv('/Users/munjismac/code/munjik/personal-projects/real_estate_project/RawData.csv')\n",
    "df2 = pd.read_csv('/Users/munjismac/code/munjik/personal-projects/real_estate_project/Data-(Jan20-June20).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41236ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = dataframe.drop(columns='Additional Lien')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e1dd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d533b9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd8c37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed97df97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat both dataframes\n",
    "df = pd.concat([dataframe, df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f88458",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060b2b10",
   "metadata": {},
   "source": [
    "<h2>Let's clean up some data </h2> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c623356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the unwanted columns\n",
    "df = df.drop(columns=['CASE #', 'Special Master','Postponed', 'Time', 'Postponed','Debtor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381d20d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(labels=128) #last column was all empty anyways\n",
    "df.isnull().sum() #check to see how many null values we have in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97acab75",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy=\"most_frequent\") # Instanciate a SimpleImputer object with strategy of choice\n",
    "# impute lender\n",
    "imputer.fit(df[['ARV']]) # Call the \"fit\" method on the object\n",
    "df['ARV'] = imputer.transform(df[['ARV']]) # Call the \"transform\" method on the object\n",
    "\n",
    "imputer.fit(df[['EQUITY']]) # Call the \"fit\" method on the object\n",
    "df['EQUITY'] = imputer.transform(df[['EQUITY']]) # Call the \"transform\" method on the object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080feb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7b2f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2a6829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove puncuation\n",
    "def remove_dollar(x):\n",
    "    return x.replace('$','')\n",
    "def replace_comma(x):\n",
    "    return x.replace(',','')\n",
    "def replace_period(x):\n",
    "    return x.replace('.','')\n",
    "def replace_paran(x):\n",
    "    return x.replace(\"(\",\"\").replace(\")\",\"\")\n",
    "# reformat from str to float\n",
    "def currency_to_float(x: str) -> float:\n",
    "    \"\"\"Converts US currency ``x`` to float.\"\"\"\n",
    "    return float(x)\n",
    "    \n",
    "#-> potentially use this function to do all in one functions here\n",
    "# Convert the currency to float.\n",
    "# def currency_to_float(x: str) -> float:\n",
    "#     \"\"\"Converts US currency ``x`` to float.\"\"\"\n",
    "#     return float(x.replace(\"$\", \"\").replace(\",\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab0f546",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sold'] = df['Sold'].astype('str')\n",
    "df['Sold'] = df['Sold'].apply(remove_dollar)\n",
    "df['Sold'] = df['Sold'].apply(replace_comma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b194db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.Sold) == 'THEY DONT HAVE ANYTHING ON THIS...he\\'ll double check when back at office']\n",
    "df.iloc[63]['Sold'] = 'NaN'\n",
    "df['Sold'] = df['Sold'].apply(lambda x: currency_to_float(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbe88f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum should have increased from 92 to 93\n",
    "df['Sold'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f2b870",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_imputer = SimpleImputer(strategy=\"mean\") # Instanciate a SimpleImputer object with strategy of choice\n",
    "mean_imputer.fit(df[['Sold']]) # Call the \"fit\" method on the object\n",
    "df['Sold'] = mean_imputer.transform(df[['Sold']]) # Call the \"transform\" method on the object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5f64fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sold'].isnull().sum() #now should be zero once we fill the values in with imputes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e52ceca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First convert to type string -> clean Balance column\n",
    "df['Balance'] = df['Balance'].astype('str')\n",
    "df['Balance'] = df['Balance'].apply(replace_comma)\n",
    "df['Balance'] = df['Balance'].apply(remove_dollar)\n",
    "\n",
    "# First convert to type string -> clean ARV column\n",
    "df['ARV'] = df['ARV'].astype('str')\n",
    "df['ARV'] = df['ARV'].apply(replace_comma)\n",
    "df['ARV'] = df['ARV'].apply(remove_dollar)\n",
    "# First convert to type string -> clean Equity column\n",
    "df['EQUITY'] = df['EQUITY'].astype('str')\n",
    "df['EQUITY'] = df['EQUITY'].apply(replace_comma)\n",
    "df['EQUITY'] = df['EQUITY'].apply(remove_dollar)\n",
    "df['EQUITY'] = df['EQUITY'].apply(replace_paran)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a64bb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXING THIS ERROR: ValueError: could not convert string to float: 'COMMERCIAL'\n",
    "df[(df.ARV) == 'COMMERCIAL'] #find location\n",
    "df.loc[df.ARV == \"COMMERCIAL\", \"ARV\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa896e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum() #sum for ARV has gone up to 1 because of code above\n",
    "mean_imputer.fit(df[['ARV']]) # Call the \"fit\" method on the object\n",
    "df['ARV'] = mean_imputer.transform(df[['ARV']]) # Call the \"transform\" method on the object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4c46f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_imputer.statistics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591b7ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Balance'] = df['Balance'].apply(lambda x: currency_to_float(x))\n",
    "df['ARV'] = df['ARV'].apply(lambda x: currency_to_float(x))\n",
    "df['EQUITY'] = df['EQUITY'].apply(lambda x: currency_to_float(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58adbe55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets convert Date to datetime64\n",
    "df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3342a783",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403d1d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to concatante all coordinates into 1 for lats and longs in next step\n",
    "def coordinates(dataframe_coord):\n",
    "    cols = [\"Address\", \"City\",\"State\",\"Zip\"]\n",
    "    df['coordinates'] = df[cols].apply(lambda row: ','.join(row.values.astype(str)), axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7498ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1091ed1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn our new coordinates column into Lats and Longs\n",
    "def geolocate(dataframe):\n",
    "    df_address = dataframe['coordinates']\n",
    "    lats = []\n",
    "    lngs = []\n",
    "    #loop through or dataframe addresses\n",
    "    for address in df_address:\n",
    "        API_KEY = 'GGTqpEquAqOeHelGwevtJopD2QhYtUKl'\n",
    "        base_url = 'http://www.mapquestapi.com/geocoding/v1/address'\n",
    "        location = address\n",
    "\n",
    "        #call the api function on all of our addresses\n",
    "        params = {\n",
    "            'key': API_KEY,\n",
    "            'location' : location\n",
    "        }\n",
    "\n",
    "        response = requests.get(base_url,params=params).json()\n",
    "        results = response['results'][0]\n",
    "        lat = results['locations'][0]['latLng']['lat']\n",
    "        lng = results['locations'][0]['latLng']['lng']\n",
    "        lats.append(lat)\n",
    "        lngs.append(lng)\n",
    "    df_location = pd.DataFrame(list(zip(lats,lngs)),\n",
    "                           columns=['location_lats', 'location_lngs'])\n",
    "    dataframe = pd.concat([dataframe,df_location], axis=1)\n",
    "    return dataframe\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376d74b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc[46])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d657b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6708a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping this column with useless info\n",
    "df = df.drop([df.index[46]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8d3844",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resets index to 0\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b8019b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = geolocate(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c8c805",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627ce3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"FOR REFERENCE ->\n",
    "One Hot Encoding:\n",
    "We use this categorical data encoding technique when the features are nominal(do not have any order)\n",
    "------------------------------------------------------------------------------------------------\n",
    "Label Encoding or Ordinal Encoding:\n",
    "We use this categorical data encoding technique when the categorical feature is ordinal. In this case,\n",
    "retaining the order is important. Hence encoding should reflect the sequence.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a70f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.Lender.nunique()) #OHE this or see next best step for 33 diff lenders\n",
    "print(df.Address.nunique()) #--> I'd like to change this to Lat's and Longs for ML model\n",
    "print(df.City.nunique()) #Encode this ? I think\n",
    "print(df.State.nunique()) #easy encode all 1's\n",
    "print(df.Zip.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41887260",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets drop address and coordinates since we now have lats and longs\n",
    "df = df.drop(columns=['Address', 'coordinates'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab423aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a018a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change Zip to INT64 instead of current object\n",
    "df['Zip'] = df['Zip'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97048c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#begin OHE\n",
    "ohc = OneHotEncoder()\n",
    "ohe = ohc.fit_transform(df.Lender.values.reshape(-1,1)).toarray()\n",
    "\n",
    "dfOneHot = pd.DataFrame(ohe, columns=['Lender_' +str(ohc.categories_[0][i]) for i in range(len(ohc.categories_[0]))])\n",
    "dfh = pd.concat([df, dfOneHot], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1135eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a00fc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOneHot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101eb113",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb8cbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting off by starting to see what is selling above judgement and %%% sold vs Scheduled "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83106e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.)if sold is above balanced \n",
    "#2.) change the objects to their types\n",
    "#3.) NaN == 0\n",
    "#4.) Banks to individual #'s' 1 - 33 top 10 banks\n",
    "# data[(data.Medal == 'Silver') & (data.Gender == 'Men')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a30e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR TESTING PURPOSES ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2b913d",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_dataframe = df.drop(columns=['Lender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba58d133",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988b450c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract month feature\n",
    "months = df.Date.dt.month\n",
    "#extract day of month feature\n",
    "day_of_months = df.Date.dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f409d36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a dataframe with months and day of months \n",
    "data_feature = pd.DataFrame({\n",
    "    'months':months,\n",
    "    'days': day_of_months\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72eee63",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = pd.concat([testing_dataframe, data_feature], axis=1)\n",
    "feature = feature.drop(columns='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fcb2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OHE city, NM, and ZIP.\n",
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22546c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()\n",
    "ohe.fit(feature[['State']]) # Fit encoder\n",
    "feature['State'] = ohe.transform(feature[['State']]).toarray() # Encode Street"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3642a74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use BinaryEncoder for ZIP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc5434d",
   "metadata": {},
   "source": [
    "<h2>Will work on this once basic model idea is done.. for now still quite of feature engineering to be done </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9b5a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohc = OneHotEncoder()\n",
    "final_ohe = ohc.fit_transform(feature.City.values.reshape(-1,1)).toarray()\n",
    "final_dfOneHot = pd.DataFrame(final_ohe, columns=['City_'+str(ohc.categories_[0][i]) for i in range(len(ohc.categories_[0]))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f76912",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dfOneHot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1e7a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfc140a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = pd.concat([feature, final_dfOneHot], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e5b513",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = feature.drop(columns='City')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca993cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = feature.drop(columns='Zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da351d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = feature.drop(columns='State')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6e6ac5",
   "metadata": {},
   "source": [
    "<h2>The ML Alog's to use is KNN Regression(k-NN) and Random Forest (RF) Regression </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadf4aba",
   "metadata": {},
   "source": [
    "<p>1.) Will begin with RFF since there's no feature scaling required. KNN and any distance is preferred to same scale. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb74028",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualise the data\n",
    "# correlation \n",
    "corr = feature.corr()\n",
    "top_corr_feat = corr.index\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.heatmap(feature[top_corr_feat].corr(), annot=True, fmt='.0%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7b5914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X and y features\n",
    "X = feature.drop(columns='Sold')\n",
    "y = feature['Sold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e8764c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor #import library\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "model = RandomForestRegressor() #instantiate our Basic model , no hyper parameters yet \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = .3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42969a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7878a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed18c754",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a873105b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y_test - predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeac94fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test,predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3f7a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718d6fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066ee10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b26736f",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_values = y_test\n",
    "plt.scatter(predictions, actual_values, alpha=.7,\n",
    "            color='b') #alpha helps to show overlapping data\n",
    "plt.xlabel('Predicted Price')\n",
    "plt.ylabel('Actual Price')\n",
    "plt.title('Linear Regression Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a37d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ax = range(len(y_test))\n",
    "plt.plot(x_ax, y_test, label=\"original\")\n",
    "plt.plot(x_ax, predictions[:126], label=\"predicted\")\n",
    "plt.title(\"House test and predicted data\")\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis')\n",
    "plt.legend(loc='best',fancybox=True, shadow=True)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6253597e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
