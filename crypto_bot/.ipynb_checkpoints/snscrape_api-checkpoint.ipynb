{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1064c38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install git+https://github.com/JustAnotherArchivist/snscrape.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9aa92c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Using TwitterSearchScraper to scrape data and append tweets to list\n",
    "# for i,tweet in enumerate(sntwitter.TwitterSearchScraper('$BTC').get_items()):\n",
    "#     if i > 300:\n",
    "#         break\n",
    "#     tweets_list.append([tweet.date, tweet.content])\n",
    "# # # Creating a dataframe from the tweets list above\n",
    "# tweets_df = pd.DataFrame(tweets_list, columns=['created_at', 'full_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1784499f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# import tensorflow_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9a87c5ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.0'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install tensorflow-gpu==2.4.1\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b3b23e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-text==2.4.1\n",
      "  Downloading tensorflow_text-2.4.1-cp38-cp38-macosx_10_9_x86_64.whl (2.8 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.8 MB 2.5 MB/s eta 0:00:01     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                         | 542 kB 1.2 MB/s eta 0:00:02     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè              | 1.5 MB 1.2 MB/s eta 0:00:02\n",
      "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /Users/munjikahalah/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorflow-text==2.4.1) (0.12.0)\n",
      "Collecting tensorflow<2.5,>=2.4.0\n",
      "  Downloading tensorflow-2.4.4-cp38-cp38-macosx_10_14_x86_64.whl (174.3 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 174.3 MB 3.1 MB/s eta 0:00:01   |‚ñä                               | 3.7 MB 4.1 MB/s eta 0:00:42     |‚ñà‚ñà‚ñè                             | 12.0 MB 2.9 MB/s eta 0:00:56     |‚ñà‚ñà‚ñä                             | 14.6 MB 3.1 MB/s eta 0:00:51     |‚ñà‚ñà‚ñà‚ñã                            | 19.8 MB 3.3 MB/s eta 0:00:48     |‚ñà‚ñà‚ñà‚ñà                            | 22.2 MB 3.9 MB/s eta 0:00:40     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                          | 33.2 MB 3.8 MB/s eta 0:00:37     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                     | 59.6 MB 3.7 MB/s eta 0:00:32     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                    | 60.9 MB 3.7 MB/s eta 0:00:31     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                   | 68.1 MB 3.9 MB/s eta 0:00:28     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                  | 73.9 MB 4.0 MB/s eta 0:00:25     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                  | 75.2 MB 3.0 MB/s eta 0:00:33     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà         | 125.5 MB 4.2 MB/s eta 0:00:12     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 157.1 MB 3.7 MB/s eta 0:00:05     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 158.9 MB 3.7 MB/s eta 0:00:05     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 159.2 MB 3.7 MB/s eta 0:00:05     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 160.9 MB 3.7 MB/s eta 0:00:04\n",
      "\u001b[?25hCollecting grpcio~=1.32.0\n",
      "  Downloading grpcio-1.32.0-cp38-cp38-macosx_10_9_x86_64.whl (3.3 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.3 MB 3.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gast==0.3.3\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: tensorboard~=2.4 in /Users/munjikahalah/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text==2.4.1) (2.7.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /Users/munjikahalah/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text==2.4.1) (1.6.3)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /Users/munjikahalah/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text==2.4.1) (3.7.4.3)\n",
      "Requirement already satisfied: six~=1.15.0 in /Users/munjikahalah/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text==2.4.1) (1.15.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /Users/munjikahalah/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text==2.4.1) (1.1.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /Users/munjikahalah/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text==2.4.1) (3.3.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /Users/munjikahalah/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text==2.4.1) (0.2.0)\n",
      "Collecting h5py~=2.10.0\n",
      "  Downloading h5py-2.10.0-cp38-cp38-macosx_10_9_x86_64.whl (3.0 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.0 MB 3.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wrapt~=1.12.1 in /Users/munjikahalah/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text==2.4.1) (1.12.1)\n",
      "Requirement already satisfied: wheel~=0.35 in /Users/munjikahalah/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text==2.4.1) (0.36.2)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /Users/munjikahalah/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text==2.4.1) (1.19.5)\n",
      "Collecting tensorflow-estimator<2.5.0,>=2.4.0\n",
      "  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 462 kB 3.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: keras-preprocessing~=1.1.2 in /Users/munjikahalah/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text==2.4.1) (1.1.2)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /Users/munjikahalah/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text==2.4.1) (3.17.3)\n",
      "Requirement already satisfied: absl-py~=0.10 in /Users/munjikahalah/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text==2.4.1) (0.12.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /Users/munjikahalah/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text==2.4.1) (1.12)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/munjikahalah/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text==2.4.1) (1.32.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/munjikahalah/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text==2.4.1) (2.0.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/munjikahalah/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text==2.4.1) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/munjikahalah/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text==2.4.1) (0.4.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/munjikahalah/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text==2.4.1) (49.2.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/munjikahalah/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text==2.4.1) (2.25.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/munjikahalah/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text==2.4.1) (1.8.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/munjikahalah/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text==2.4.1) (3.3.4)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/munjikahalah/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text==2.4.1) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/munjikahalah/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text==2.4.1) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/munjikahalah/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text==2.4.1) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/munjikahalah/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text==2.4.1) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/munjikahalah/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text==2.4.1) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/munjikahalah/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text==2.4.1) (1.26.6)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/munjikahalah/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text==2.4.1) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/munjikahalah/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text==2.4.1) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/munjikahalah/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text==2.4.1) (2021.5.30)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/munjikahalah/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text==2.4.1) (3.1.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: grpcio, tensorflow-estimator, h5py, gast, tensorflow, tensorflow-text\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.41.1\n",
      "    Uninstalling grpcio-1.41.1:\n",
      "      Successfully uninstalled grpcio-1.41.1\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.5.0\n",
      "    Uninstalling tensorflow-estimator-2.5.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.1.0\n",
      "    Uninstalling h5py-3.1.0:\n",
      "      Successfully uninstalled h5py-3.1.0\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.4.0\n",
      "    Uninstalling gast-0.4.0:\n",
      "      Successfully uninstalled gast-0.4.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.6.1\n",
      "    Uninstalling tensorflow-2.6.1:\n",
      "      Successfully uninstalled tensorflow-2.6.1\n",
      "  Attempting uninstall: tensorflow-text\n",
      "    Found existing installation: tensorflow-text 2.6.0\n",
      "    Uninstalling tensorflow-text-2.6.0:\n",
      "      Successfully uninstalled tensorflow-text-2.6.0\n",
      "Successfully installed gast-0.3.3 grpcio-1.32.0 h5py-2.10.0 tensorflow-2.4.4 tensorflow-estimator-2.4.0 tensorflow-text-2.4.1\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/Users/munjikahalah/.pyenv/versions/3.8.6/envs/lewagon/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow-text==2.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c84f29a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replacen(x):\n",
    "    return x.replace('\\n','')\n",
    "def replacer(x):\n",
    "    return x.replace('\\r','')\n",
    "def replacern(x):\n",
    "    return x.replace('\\r\\n','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0da1300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    df['full_text'] = df['full_text'].apply(replacer)\n",
    "    df['full_text'] = df['full_text'].apply(replacen)\n",
    "    df['full_text'] = df['full_text'].apply(replacern)\n",
    "    return df\n",
    "def remove_dollar(l):\n",
    "    new_list = []\n",
    "    for item in l:\n",
    "        new_list.append(item.replace('$',''))\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66446e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(text):\n",
    "    text = re.sub(r'https?://\\S+', '', text)\n",
    "    return text\n",
    "def remove_url(df):\n",
    "    df['full_text'] = df['full_text'].apply(remove_urls)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63d323ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tickers(text):\n",
    "    return re.findall(r'[$][A-Za-z][\\S]*', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c36d7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using TwitterSearchScraper to scrape data and append tweets to list\n",
    "duplicated_tweet = []\n",
    "def get_tweets(tickers):\n",
    "    tweets_list = []\n",
    "    for i,tweet in enumerate(sntwitter.TwitterSearchScraper('${}'.format(tickers)).get_items()):\n",
    "        if i > 1000:\n",
    "            break\n",
    "        tweets_list.append([tweet.date, tweet.content])\n",
    "        tweet_df = pd.DataFrame(tweets_list, columns=['created_at', 'full_text'])\n",
    "        duplicated_tweet.append( tweet_df.sum().duplicated())\n",
    "        tweet_df['symbols'] = tweet_df['full_text'].apply(find_tickers)\n",
    "        tweet_df['symbols'] = tweet_df['symbols'].apply(remove_dollar)\n",
    "        download_yahoo_stocks(tickers= tickers, period='6mo')\n",
    "        \n",
    "    return tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ad5abb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_tweets('SOL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c060cdd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fw/j6mc6mcd20379_z864ff2bfw0000gn/T/ipykernel_15395/3011636862.py:10: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  duplicated_tweet.append( tweet_df.sum().duplicated())\n"
     ]
    }
   ],
   "source": [
    "dataframe = get_tweets('DOGE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7c5f473",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = clean_data(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "601fcd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_matrix(df):\n",
    "    embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual/3\")\n",
    "    text_result = embed(df['full_text'])\n",
    "    vector_df = pd.DataFrame(text_result.numpy())\n",
    "    return vector_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a24cd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = remove_url(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c930cc71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@BadLuckBanana1 This is not about NFTs, i want to talk about a #Crypto i think is the next big one, if you're not interested remember that you were not interested in $Bit $Eth $Doge $shib years ago and ask to your friends who know about #altcoin to check this out $Tking\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.full_text[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17499bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_datetime(df):\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64870092",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_tweets_per_day(df):\n",
    "    ticker_mean_df = df.groupby('created_at').mean().reset_index()\n",
    "    print(f'TICKER MEAN DF SHAPE =========== {ticker_mean_df.shape}')\n",
    "    return ticker_mean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9250233d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def download_yahoo_stocks(tickers=tickers, period = \"6mo\"):\n",
    "#     tickers = yf.download(tickers = tickers, interval='1d',period = period)\n",
    "\n",
    "#     INTCclose = tickers['Close']['INTC']\n",
    "#     BYNDclose = tickers['Close']['BYND']\n",
    "#     GEclose = tickers['Close']['GE']\n",
    "#     BTCclose = tickers['Close']['BTC']\n",
    "\n",
    "#     # return {\"BTC\": BTCclose, \"BYND\": BYNDclose,\n",
    "\n",
    "#     return INTCclose, BYNDclose, GEclose, BTCclose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20415abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_date_time(df):\n",
    "    if df['created_at'].dtype == 'object':\n",
    "        df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "    df['created_at'] = df['created_at'].dt.date\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "728d6176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_live_tweets_to_vectorize(dataframe):\n",
    "    df = dataframe\n",
    "    df = fix_date_time(df)\n",
    "#     df = concat_vectors(df)\n",
    "    df = embed_matrix(df)\n",
    "#     df = df_to_datetime(df)\n",
    "#     df = average_tweets_per_day(df)\n",
    "#     df = df.set_index(['created_at'])\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fedf1650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-sentencepiece\n",
      "  Downloading tf_sentencepiece-0.1.90-py2.py3-none-macosx_10_10_x86_64.whl (2.0 MB)\n",
      "     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.0 MB 2.0 MB/s            \n",
      "\u001b[?25hInstalling collected packages: tf-sentencepiece\n",
      "Successfully installed tf-sentencepiece-0.1.90\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tf-sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "907ed5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "# import tf_sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6305f356",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "dlopen(/Users/munjikahalah/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/tensorflow_text/python/metrics/_text_similarity_metric_ops.dylib, 6): Symbol not found: __ZN10tensorflow15TensorShapeBaseINS_11TensorShapeEEC2EN4absl14lts_2020_02_254SpanIKxEE\n  Referenced from: /Users/munjikahalah/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/tensorflow_text/python/metrics/_text_similarity_metric_ops.dylib\n  Expected in: /Users/munjikahalah/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/../libtensorflow_framework.2.dylib\n in /Users/munjikahalah/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/tensorflow_text/python/metrics/_text_similarity_metric_ops.dylib",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/fw/j6mc6mcd20379_z864ff2bfw0000gn/T/ipykernel_15395/101723867.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/tensorflow_text/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# pylint: disable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/tensorflow_text/python/metrics/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# pylint: disable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_similarity_metric_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Public symbols in the \"tensorflow_text.metrics\" package.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/tensorflow_text/python/metrics/text_similarity_metric_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_library\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresource_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mgen_text_similarity_metric_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_library\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_op_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_path_to_datafile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_text_similarity_metric_ops.dylib'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py\u001b[0m in \u001b[0;36mload_op_library\u001b[0;34m(library_filename)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \"\"\"\n\u001b[1;32m     57\u001b[0m   \u001b[0mlib_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpy_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_LoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibrary_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     wrappers = _pywrap_python_op_gen.GetPythonWrappers(\n\u001b[1;32m     60\u001b[0m         py_tf.TF_GetOpList(lib_handle))\n",
      "\u001b[0;31mNotFoundError\u001b[0m: dlopen(/Users/munjikahalah/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/tensorflow_text/python/metrics/_text_similarity_metric_ops.dylib, 6): Symbol not found: __ZN10tensorflow15TensorShapeBaseINS_11TensorShapeEEC2EN4absl14lts_2020_02_254SpanIKxEE\n  Referenced from: /Users/munjikahalah/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/tensorflow_text/python/metrics/_text_similarity_metric_ops.dylib\n  Expected in: /Users/munjikahalah/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/../libtensorflow_framework.2.dylib\n in /Users/munjikahalah/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/tensorflow_text/python/metrics/_text_similarity_metric_ops.dylib"
     ]
    }
   ],
   "source": [
    "import tensorflow_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dcbc50de",
   "metadata": {},
   "outputs": [],
   "source": [
    "our_live_vector = grab_live_tweets_to_vectorize(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "38521b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>full_text</th>\n",
       "      <th>symbols</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-11-03</td>\n",
       "      <td>This trader fixed $100thousands on Ethereum sh...</td>\n",
       "      <td>[eth, omg, ldx, lrc, cate, mana, avax, hot, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-11-03</td>\n",
       "      <td>@SquidGamePRO @CoinMarketCap @business @nypost...</td>\n",
       "      <td>[SQUID, Floki, Shiba, Doge, SQUID, Floki, Shib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-11-03</td>\n",
       "      <td>@himacoin I'm so excited and happy to be parti...</td>\n",
       "      <td>[HIMA, SAMO, SOL, DOGE]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-11-03</td>\n",
       "      <td>Bug√ºn patlƒ±ycak hissediyorum $DOGE #doge sende...</td>\n",
       "      <td>[DOGE]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-11-03</td>\n",
       "      <td>@himacoin This project have great potentials a...</td>\n",
       "      <td>[HIMA, SAMO, SOL, DOGE]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2021-11-02</td>\n",
       "      <td>@SquidGamePRO @CoinMarketCap @business @nypost...</td>\n",
       "      <td>[SQUID, Floki, Shiba, Doge]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2021-11-02</td>\n",
       "      <td>$DOGE | $0.27447 | $0.27484 / $0.27281 / $0.27...</td>\n",
       "      <td>[DOGE]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>2021-11-02</td>\n",
       "      <td>SIIM, MEUS QUERIDOS!O @elonmusk tamb√©m acha qu...</td>\n",
       "      <td>[DOGE., FLOKI]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>2021-11-02</td>\n",
       "      <td>@SquidGamePRO @CoinMarketCap @business @nypost...</td>\n",
       "      <td>[SQUID, Floki, Shiba, Doge]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>2021-11-02</td>\n",
       "      <td>üö® Dogecoin Daily Update üö®üìà 24HR change: 1.14% ...</td>\n",
       "      <td>[DOGE]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1001 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      created_at                                          full_text  \\\n",
       "0     2021-11-03  This trader fixed $100thousands on Ethereum sh...   \n",
       "1     2021-11-03  @SquidGamePRO @CoinMarketCap @business @nypost...   \n",
       "2     2021-11-03  @himacoin I'm so excited and happy to be parti...   \n",
       "3     2021-11-03  Bug√ºn patlƒ±ycak hissediyorum $DOGE #doge sende...   \n",
       "4     2021-11-03  @himacoin This project have great potentials a...   \n",
       "...          ...                                                ...   \n",
       "996   2021-11-02  @SquidGamePRO @CoinMarketCap @business @nypost...   \n",
       "997   2021-11-02  $DOGE | $0.27447 | $0.27484 / $0.27281 / $0.27...   \n",
       "998   2021-11-02  SIIM, MEUS QUERIDOS!O @elonmusk tamb√©m acha qu...   \n",
       "999   2021-11-02  @SquidGamePRO @CoinMarketCap @business @nypost...   \n",
       "1000  2021-11-02  üö® Dogecoin Daily Update üö®üìà 24HR change: 1.14% ...   \n",
       "\n",
       "                                                symbols  \n",
       "0     [eth, omg, ldx, lrc, cate, mana, avax, hot, co...  \n",
       "1     [SQUID, Floki, Shiba, Doge, SQUID, Floki, Shib...  \n",
       "2                               [HIMA, SAMO, SOL, DOGE]  \n",
       "3                                                [DOGE]  \n",
       "4                               [HIMA, SAMO, SOL, DOGE]  \n",
       "...                                                 ...  \n",
       "996                         [SQUID, Floki, Shiba, Doge]  \n",
       "997                                              [DOGE]  \n",
       "998                                      [DOGE., FLOKI]  \n",
       "999                         [SQUID, Floki, Shiba, Doge]  \n",
       "1000                                             [DOGE]  \n",
       "\n",
       "[1001 rows x 3 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_live_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f877a0d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
